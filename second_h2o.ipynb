{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM JBR-11.0.13.7-1751.21-jcef (build 11.0.13+7-b1751.21, mixed mode)\n",
      "  Starting server from C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpbhkubhly\n",
      "  JVM stdout: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpbhkubhly\\h2o_HP_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpbhkubhly\\h2o_HP_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>13 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Bangkok</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>14 days, 19 hours and 24 minutes </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_HP_ali52x</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.945 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.3 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O_cluster_uptime:         13 secs\n",
       "H2O_cluster_timezone:       Asia/Bangkok\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.3\n",
       "H2O_cluster_version_age:    14 days, 19 hours and 24 minutes\n",
       "H2O_cluster_name:           H2O_from_python_HP_ali52x\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.945 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.3 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start the H2O cluster (locally)\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "09:43:08.661: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20221208_94308   </td><td style=\"text-align: right;\">0.790804</td><td style=\"text-align: right;\"> 0.548481</td><td style=\"text-align: right;\">0.807638</td><td style=\"text-align: right;\">              0.313721</td><td style=\"text-align: right;\">0.431162</td><td style=\"text-align: right;\">0.1859  </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20221208_94308</td><td style=\"text-align: right;\">0.788212</td><td style=\"text-align: right;\"> 0.551536</td><td style=\"text-align: right;\">0.80462 </td><td style=\"text-align: right;\">              0.316165</td><td style=\"text-align: right;\">0.432452</td><td style=\"text-align: right;\">0.187014</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.7829  </td><td style=\"text-align: right;\"> 0.558001</td><td style=\"text-align: right;\">0.802101</td><td style=\"text-align: right;\">              0.336502</td><td style=\"text-align: right;\">0.435272</td><td style=\"text-align: right;\">0.189462</td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.779512</td><td style=\"text-align: right;\"> 0.560256</td><td style=\"text-align: right;\">0.799536</td><td style=\"text-align: right;\">              0.327511</td><td style=\"text-align: right;\">0.436609</td><td style=\"text-align: right;\">0.190627</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.778879</td><td style=\"text-align: right;\"> 0.56126 </td><td style=\"text-align: right;\">0.797195</td><td style=\"text-align: right;\">              0.329521</td><td style=\"text-align: right;\">0.43698 </td><td style=\"text-align: right;\">0.190952</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_2            </td><td style=\"text-align: right;\">0.77786 </td><td style=\"text-align: right;\"> 0.564655</td><td style=\"text-align: right;\">0.795359</td><td style=\"text-align: right;\">              0.33376 </td><td style=\"text-align: right;\">0.438088</td><td style=\"text-align: right;\">0.191921</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.776908</td><td style=\"text-align: right;\"> 0.563372</td><td style=\"text-align: right;\">0.793988</td><td style=\"text-align: right;\">              0.321192</td><td style=\"text-align: right;\">0.437927</td><td style=\"text-align: right;\">0.19178 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_3            </td><td style=\"text-align: right;\">0.772926</td><td style=\"text-align: right;\"> 0.568181</td><td style=\"text-align: right;\">0.791195</td><td style=\"text-align: right;\">              0.322808</td><td style=\"text-align: right;\">0.439997</td><td style=\"text-align: right;\">0.193598</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.771118</td><td style=\"text-align: right;\"> 0.569616</td><td style=\"text-align: right;\">0.791326</td><td style=\"text-align: right;\">              0.33599 </td><td style=\"text-align: right;\">0.441149</td><td style=\"text-align: right;\">0.194612</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_4            </td><td style=\"text-align: right;\">0.770522</td><td style=\"text-align: right;\"> 0.569244</td><td style=\"text-align: right;\">0.7891  </td><td style=\"text-align: right;\">              0.349737</td><td style=\"text-align: right;\">0.440792</td><td style=\"text-align: right;\">0.194297</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_5            </td><td style=\"text-align: right;\">0.770455</td><td style=\"text-align: right;\"> 0.573213</td><td style=\"text-align: right;\">0.788108</td><td style=\"text-align: right;\">              0.328679</td><td style=\"text-align: right;\">0.442487</td><td style=\"text-align: right;\">0.195795</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.762437</td><td style=\"text-align: right;\"> 0.58336 </td><td style=\"text-align: right;\">0.774864</td><td style=\"text-align: right;\">              0.351653</td><td style=\"text-align: right;\">0.446561</td><td style=\"text-align: right;\">0.199417</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.758648</td><td style=\"text-align: right;\"> 0.586822</td><td style=\"text-align: right;\">0.77324 </td><td style=\"text-align: right;\">              0.352727</td><td style=\"text-align: right;\">0.448252</td><td style=\"text-align: right;\">0.20093 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_1            </td><td style=\"text-align: right;\">0.747658</td><td style=\"text-align: right;\"> 0.59151 </td><td style=\"text-align: right;\">0.763211</td><td style=\"text-align: right;\">              0.359419</td><td style=\"text-align: right;\">0.451053</td><td style=\"text-align: right;\">0.203448</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20221208_94308_model_1   </td><td style=\"text-align: right;\">0.746656</td><td style=\"text-align: right;\"> 0.604281</td><td style=\"text-align: right;\">0.751953</td><td style=\"text-align: right;\">              0.340655</td><td style=\"text-align: right;\">0.453965</td><td style=\"text-align: right;\">0.206084</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20221208_94308_model_1   </td><td style=\"text-align: right;\">0.742292</td><td style=\"text-align: right;\"> 0.607226</td><td style=\"text-align: right;\">0.742176</td><td style=\"text-align: right;\">              0.36275 </td><td style=\"text-align: right;\">0.455581</td><td style=\"text-align: right;\">0.207554</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20221208_94308_model_2   </td><td style=\"text-align: right;\">0.738035</td><td style=\"text-align: right;\"> 0.600005</td><td style=\"text-align: right;\">0.745179</td><td style=\"text-align: right;\">              0.365434</td><td style=\"text-align: right;\">0.454895</td><td style=\"text-align: right;\">0.206929</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20221208_94308_model_1   </td><td style=\"text-align: right;\">0.734143</td><td style=\"text-align: right;\"> 0.627597</td><td style=\"text-align: right;\">0.740468</td><td style=\"text-align: right;\">              0.360092</td><td style=\"text-align: right;\">0.460882</td><td style=\"text-align: right;\">0.212412</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20221208_94308_model_2   </td><td style=\"text-align: right;\">0.733588</td><td style=\"text-align: right;\"> 0.612705</td><td style=\"text-align: right;\">0.741662</td><td style=\"text-align: right;\">              0.352581</td><td style=\"text-align: right;\">0.460751</td><td style=\"text-align: right;\">0.212291</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20221208_94308_model_2   </td><td style=\"text-align: right;\">0.720807</td><td style=\"text-align: right;\"> 0.629241</td><td style=\"text-align: right;\">0.720941</td><td style=\"text-align: right;\">              0.370791</td><td style=\"text-align: right;\">0.463288</td><td style=\"text-align: right;\">0.214636</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20221208_94308                </td><td style=\"text-align: right;\">0.702823</td><td style=\"text-align: right;\"> 0.630547</td><td style=\"text-align: right;\">0.710036</td><td style=\"text-align: right;\">              0.408111</td><td style=\"text-align: right;\">0.468197</td><td style=\"text-align: right;\">0.219208</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.682648</td><td style=\"text-align: right;\"> 0.63852 </td><td style=\"text-align: right;\">0.680719</td><td style=\"text-align: right;\">              0.397234</td><td style=\"text-align: right;\">0.472683</td><td style=\"text-align: right;\">0.223429</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 7 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                     auc    logloss     aucpr    mean_per_class_error      rmse       mse\n",
       "------------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20221208_94308     0.790804   0.548481  0.807638                0.313721  0.431162  0.1859\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20221208_94308  0.788212   0.551536  0.80462                 0.316165  0.432452  0.187014\n",
       "GBM_5_AutoML_1_20221208_94308                           0.7829     0.558001  0.802101                0.336502  0.435272  0.189462\n",
       "GBM_1_AutoML_1_20221208_94308                           0.779512   0.560256  0.799536                0.327511  0.436609  0.190627\n",
       "GBM_2_AutoML_1_20221208_94308                           0.778879   0.56126   0.797195                0.329521  0.43698   0.190952\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_2              0.77786    0.564655  0.795359                0.33376   0.438088  0.191921\n",
       "GBM_3_AutoML_1_20221208_94308                           0.776908   0.563372  0.793988                0.321192  0.437927  0.19178\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_3              0.772926   0.568181  0.791195                0.322808  0.439997  0.193598\n",
       "GBM_4_AutoML_1_20221208_94308                           0.771118   0.569616  0.791326                0.33599   0.441149  0.194612\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_4              0.770522   0.569244  0.7891                  0.349737  0.440792  0.194297\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_5              0.770455   0.573213  0.788108                0.328679  0.442487  0.195795\n",
       "DRF_1_AutoML_1_20221208_94308                           0.762437   0.58336   0.774864                0.351653  0.446561  0.199417\n",
       "XRT_1_AutoML_1_20221208_94308                           0.758648   0.586822  0.77324                 0.352727  0.448252  0.20093\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_1              0.747658   0.59151   0.763211                0.359419  0.451053  0.203448\n",
       "DeepLearning_grid_2_AutoML_1_20221208_94308_model_1     0.746656   0.604281  0.751953                0.340655  0.453965  0.206084\n",
       "DeepLearning_grid_3_AutoML_1_20221208_94308_model_1     0.742292   0.607226  0.742176                0.36275   0.455581  0.207554\n",
       "DeepLearning_grid_2_AutoML_1_20221208_94308_model_2     0.738035   0.600005  0.745179                0.365434  0.454895  0.206929\n",
       "DeepLearning_grid_1_AutoML_1_20221208_94308_model_1     0.734143   0.627597  0.740468                0.360092  0.460882  0.212412\n",
       "DeepLearning_grid_3_AutoML_1_20221208_94308_model_2     0.733588   0.612705  0.741662                0.352581  0.460751  0.212291\n",
       "DeepLearning_grid_1_AutoML_1_20221208_94308_model_2     0.720807   0.629241  0.720941                0.370791  0.463288  0.214636\n",
       "DeepLearning_1_AutoML_1_20221208_94308                  0.702823   0.630547  0.710036                0.408111  0.468197  0.219208\n",
       "GLM_1_AutoML_1_20221208_94308                           0.682648   0.63852   0.680719                0.397234  0.472683  0.223429\n",
       "[22 rows x 7 columns]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv\")\n",
    "test = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv\")\n",
    "\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"response\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "\n",
    "# Run AutoML for 20 base models\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# To generate predictions on a test set, you can make predictions\n",
    "# directly on the `H2OAutoML` object or on the leader model\n",
    "# object directly\n",
    "preds = aml.predict(test)\n",
    "\n",
    "# or:\n",
    "preds = aml.leader.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.706122</td><td style=\"text-align: right;\">0.293878</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.716793</td><td style=\"text-align: right;\">0.283207</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.50558 </td><td style=\"text-align: right;\">0.49442 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.337392</td><td style=\"text-align: right;\">0.662608</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.674408</td><td style=\"text-align: right;\">0.325592</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.227664</td><td style=\"text-align: right;\">0.772336</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.267522</td><td style=\"text-align: right;\">0.732478</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.605527</td><td style=\"text-align: right;\">0.394473</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.54513 </td><td style=\"text-align: right;\">0.45487 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.80452 </td><td style=\"text-align: right;\">0.19548 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[5000 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict        p0        p1\n",
       "---------  --------  --------\n",
       "        0  0.706122  0.293878\n",
       "        0  0.716793  0.283207\n",
       "        1  0.50558   0.49442\n",
       "        1  0.337392  0.662608\n",
       "        0  0.674408  0.325592\n",
       "        1  0.227664  0.772336\n",
       "        1  0.267522  0.732478\n",
       "        1  0.605527  0.394473\n",
       "        1  0.54513   0.45487\n",
       "        0  0.80452   0.19548\n",
       "[5000 rows x 3 columns]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20221208_94308   </td><td style=\"text-align: right;\">0.790804</td><td style=\"text-align: right;\"> 0.548481</td><td style=\"text-align: right;\">0.807638</td><td style=\"text-align: right;\">              0.313721</td><td style=\"text-align: right;\">0.431162</td><td style=\"text-align: right;\">0.1859  </td><td style=\"text-align: right;\">             10880</td><td style=\"text-align: right;\">                 0.075363</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20221208_94308</td><td style=\"text-align: right;\">0.788212</td><td style=\"text-align: right;\"> 0.551536</td><td style=\"text-align: right;\">0.80462 </td><td style=\"text-align: right;\">              0.316165</td><td style=\"text-align: right;\">0.432452</td><td style=\"text-align: right;\">0.187014</td><td style=\"text-align: right;\">              5724</td><td style=\"text-align: right;\">                 0.032572</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.7829  </td><td style=\"text-align: right;\"> 0.558001</td><td style=\"text-align: right;\">0.802101</td><td style=\"text-align: right;\">              0.336502</td><td style=\"text-align: right;\">0.435272</td><td style=\"text-align: right;\">0.189462</td><td style=\"text-align: right;\">               692</td><td style=\"text-align: right;\">                 0.008669</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.779512</td><td style=\"text-align: right;\"> 0.560256</td><td style=\"text-align: right;\">0.799536</td><td style=\"text-align: right;\">              0.327511</td><td style=\"text-align: right;\">0.436609</td><td style=\"text-align: right;\">0.190627</td><td style=\"text-align: right;\">              1667</td><td style=\"text-align: right;\">                 0.009391</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.778879</td><td style=\"text-align: right;\"> 0.56126 </td><td style=\"text-align: right;\">0.797195</td><td style=\"text-align: right;\">              0.329521</td><td style=\"text-align: right;\">0.43698 </td><td style=\"text-align: right;\">0.190952</td><td style=\"text-align: right;\">               768</td><td style=\"text-align: right;\">                 0.00779 </td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_2            </td><td style=\"text-align: right;\">0.77786 </td><td style=\"text-align: right;\"> 0.564655</td><td style=\"text-align: right;\">0.795359</td><td style=\"text-align: right;\">              0.33376 </td><td style=\"text-align: right;\">0.438088</td><td style=\"text-align: right;\">0.191921</td><td style=\"text-align: right;\">               806</td><td style=\"text-align: right;\">                 0.007753</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.776908</td><td style=\"text-align: right;\"> 0.563372</td><td style=\"text-align: right;\">0.793988</td><td style=\"text-align: right;\">              0.321192</td><td style=\"text-align: right;\">0.437927</td><td style=\"text-align: right;\">0.19178 </td><td style=\"text-align: right;\">               790</td><td style=\"text-align: right;\">                 0.008623</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_3            </td><td style=\"text-align: right;\">0.772926</td><td style=\"text-align: right;\"> 0.568181</td><td style=\"text-align: right;\">0.791195</td><td style=\"text-align: right;\">              0.322808</td><td style=\"text-align: right;\">0.439997</td><td style=\"text-align: right;\">0.193598</td><td style=\"text-align: right;\">              1601</td><td style=\"text-align: right;\">                 0.008526</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20221208_94308                         </td><td style=\"text-align: right;\">0.771118</td><td style=\"text-align: right;\"> 0.569616</td><td style=\"text-align: right;\">0.791326</td><td style=\"text-align: right;\">              0.33599 </td><td style=\"text-align: right;\">0.441149</td><td style=\"text-align: right;\">0.194612</td><td style=\"text-align: right;\">               986</td><td style=\"text-align: right;\">                 0.007866</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20221208_94308_model_4            </td><td style=\"text-align: right;\">0.770522</td><td style=\"text-align: right;\"> 0.569244</td><td style=\"text-align: right;\">0.7891  </td><td style=\"text-align: right;\">              0.349737</td><td style=\"text-align: right;\">0.440792</td><td style=\"text-align: right;\">0.194297</td><td style=\"text-align: right;\">              1143</td><td style=\"text-align: right;\">                 0.009973</td><td>GBM            </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                     auc    logloss     aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "------------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------  ------------------  -------------------------  ---------------\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20221208_94308     0.790804   0.548481  0.807638                0.313721  0.431162  0.1859                 10880                   0.075363  StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20221208_94308  0.788212   0.551536  0.80462                 0.316165  0.432452  0.187014                5724                   0.032572  StackedEnsemble\n",
       "GBM_5_AutoML_1_20221208_94308                           0.7829     0.558001  0.802101                0.336502  0.435272  0.189462                 692                   0.008669  GBM\n",
       "GBM_1_AutoML_1_20221208_94308                           0.779512   0.560256  0.799536                0.327511  0.436609  0.190627                1667                   0.009391  GBM\n",
       "GBM_2_AutoML_1_20221208_94308                           0.778879   0.56126   0.797195                0.329521  0.43698   0.190952                 768                   0.00779   GBM\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_2              0.77786    0.564655  0.795359                0.33376   0.438088  0.191921                 806                   0.007753  GBM\n",
       "GBM_3_AutoML_1_20221208_94308                           0.776908   0.563372  0.793988                0.321192  0.437927  0.19178                  790                   0.008623  GBM\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_3              0.772926   0.568181  0.791195                0.322808  0.439997  0.193598                1601                   0.008526  GBM\n",
       "GBM_4_AutoML_1_20221208_94308                           0.771118   0.569616  0.791326                0.33599   0.441149  0.194612                 986                   0.007866  GBM\n",
       "GBM_grid_1_AutoML_1_20221208_94308_model_4              0.770522   0.569244  0.7891                  0.349737  0.440792  0.194297                1143                   0.009973  GBM\n",
       "[22 rows x 10 columns]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get leaderboard with all possible columns\n",
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  response</th><th style=\"text-align: right;\">      x1</th><th style=\"text-align: right;\">       x2</th><th style=\"text-align: right;\">       x3</th><th style=\"text-align: right;\">      x4</th><th style=\"text-align: right;\">        x5</th><th style=\"text-align: right;\">      x6</th><th style=\"text-align: right;\">        x7</th><th style=\"text-align: right;\">       x8</th><th style=\"text-align: right;\">     x9</th><th style=\"text-align: right;\">     x10</th><th style=\"text-align: right;\">        x11</th><th style=\"text-align: right;\">       x12</th><th style=\"text-align: right;\">    x13</th><th style=\"text-align: right;\">     x14</th><th style=\"text-align: right;\">       x15</th><th style=\"text-align: right;\">      x16</th><th style=\"text-align: right;\">    x17</th><th style=\"text-align: right;\">     x18</th><th style=\"text-align: right;\">        x19</th><th style=\"text-align: right;\">       x20</th><th style=\"text-align: right;\">    x21</th><th style=\"text-align: right;\">     x22</th><th style=\"text-align: right;\">     x23</th><th style=\"text-align: right;\">     x24</th><th style=\"text-align: right;\">     x25</th><th style=\"text-align: right;\">     x26</th><th style=\"text-align: right;\">     x27</th><th style=\"text-align: right;\">     x28</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">0.623878</td><td style=\"text-align: right;\"> 0.459659</td><td style=\"text-align: right;\">-0.316512</td><td style=\"text-align: right;\">1.55701 </td><td style=\"text-align: right;\"> 0.644784 </td><td style=\"text-align: right;\">0.455929</td><td style=\"text-align: right;\">-2.24983  </td><td style=\"text-align: right;\">-0.361949</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.832978</td><td style=\"text-align: right;\"> 1.41147   </td><td style=\"text-align: right;\"> 1.52846  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.722857</td><td style=\"text-align: right;\"> 1.00964  </td><td style=\"text-align: right;\"> 0.999539</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.19099 </td><td style=\"text-align: right;\"> 0.81404   </td><td style=\"text-align: right;\">-0.879803 </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.583344</td><td style=\"text-align: right;\">0.790246</td><td style=\"text-align: right;\">1.04087 </td><td style=\"text-align: right;\">0.848858</td><td style=\"text-align: right;\">0.229702</td><td style=\"text-align: right;\">0.65594 </td><td style=\"text-align: right;\">0.677857</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">1.68204 </td><td style=\"text-align: right;\"> 0.774251</td><td style=\"text-align: right;\"> 1.32875 </td><td style=\"text-align: right;\">0.234729</td><td style=\"text-align: right;\">-0.55783  </td><td style=\"text-align: right;\">0.442921</td><td style=\"text-align: right;\">-0.0832048</td><td style=\"text-align: right;\"> 1.08119 </td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">1.14585 </td><td style=\"text-align: right;\"> 0.16228   </td><td style=\"text-align: right;\">-0.268187 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.21407 </td><td style=\"text-align: right;\"> 0.194966 </td><td style=\"text-align: right;\">-1.15627 </td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.01915 </td><td style=\"text-align: right;\">-0.759163  </td><td style=\"text-align: right;\"> 0.136347 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.94183 </td><td style=\"text-align: right;\">0.941976</td><td style=\"text-align: right;\">0.98816 </td><td style=\"text-align: right;\">0.86435 </td><td style=\"text-align: right;\">0.835132</td><td style=\"text-align: right;\">0.767871</td><td style=\"text-align: right;\">0.833013</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">1.09403 </td><td style=\"text-align: right;\">-0.88734 </td><td style=\"text-align: right;\"> 0.949229</td><td style=\"text-align: right;\">0.410261</td><td style=\"text-align: right;\">-1.55868  </td><td style=\"text-align: right;\">0.523352</td><td style=\"text-align: right;\"> 0.131675 </td><td style=\"text-align: right;\"> 0.304513</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.11916 </td><td style=\"text-align: right;\"> 1.09383   </td><td style=\"text-align: right;\">-0.396352 </td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">0.6289  </td><td style=\"text-align: right;\"> 0.628245 </td><td style=\"text-align: right;\"> 1.45775 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.523082</td><td style=\"text-align: right;\"> 0.508394  </td><td style=\"text-align: right;\"> 0.988137 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.929989</td><td style=\"text-align: right;\">0.973742</td><td style=\"text-align: right;\">0.989141</td><td style=\"text-align: right;\">0.780519</td><td style=\"text-align: right;\">0.749821</td><td style=\"text-align: right;\">0.887545</td><td style=\"text-align: right;\">0.925278</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">1.33871 </td><td style=\"text-align: right;\">-0.899027</td><td style=\"text-align: right;\">-1.25534 </td><td style=\"text-align: right;\">0.884285</td><td style=\"text-align: right;\">-0.747925 </td><td style=\"text-align: right;\">0.547445</td><td style=\"text-align: right;\">-0.79518  </td><td style=\"text-align: right;\"> 0.174235</td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.771663</td><td style=\"text-align: right;\">-0.31855   </td><td style=\"text-align: right;\"> 1.02356  </td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">0.408495</td><td style=\"text-align: right;\">-1.1431   </td><td style=\"text-align: right;\"> 0.139699</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.29395 </td><td style=\"text-align: right;\">-1.34131   </td><td style=\"text-align: right;\"> 1.61685  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.79204 </td><td style=\"text-align: right;\">0.76921 </td><td style=\"text-align: right;\">0.984082</td><td style=\"text-align: right;\">1.06928 </td><td style=\"text-align: right;\">0.700852</td><td style=\"text-align: right;\">0.83083 </td><td style=\"text-align: right;\">0.71671 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">0.699095</td><td style=\"text-align: right;\"> 1.43363 </td><td style=\"text-align: right;\">-1.72253 </td><td style=\"text-align: right;\">0.650113</td><td style=\"text-align: right;\">-0.167574 </td><td style=\"text-align: right;\">0.967464</td><td style=\"text-align: right;\"> 0.737696 </td><td style=\"text-align: right;\">-0.886391</td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">1.66797 </td><td style=\"text-align: right;\"> 0.446892  </td><td style=\"text-align: right;\"> 0.851008 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.59641 </td><td style=\"text-align: right;\"> 0.156736 </td><td style=\"text-align: right;\"> 0.340513</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.694684</td><td style=\"text-align: right;\">-0.00046069</td><td style=\"text-align: right;\">-1.14949  </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.714182</td><td style=\"text-align: right;\">0.839843</td><td style=\"text-align: right;\">0.984067</td><td style=\"text-align: right;\">0.917766</td><td style=\"text-align: right;\">0.388553</td><td style=\"text-align: right;\">0.91664 </td><td style=\"text-align: right;\">0.886331</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.842208</td><td style=\"text-align: right;\">-0.144202</td><td style=\"text-align: right;\">-1.702   </td><td style=\"text-align: right;\">0.685875</td><td style=\"text-align: right;\"> 0.544338 </td><td style=\"text-align: right;\">0.578774</td><td style=\"text-align: right;\">-0.221837 </td><td style=\"text-align: right;\">-0.586474</td><td style=\"text-align: right;\">1.08654</td><td style=\"text-align: right;\">0.909401</td><td style=\"text-align: right;\"> 2.81316   </td><td style=\"text-align: right;\">-0.0706666</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.54986 </td><td style=\"text-align: right;\">-0.85182  </td><td style=\"text-align: right;\"> 1.58811 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.14986 </td><td style=\"text-align: right;\"> 0.590011  </td><td style=\"text-align: right;\"> 0.0597691</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.872279</td><td style=\"text-align: right;\">0.684341</td><td style=\"text-align: right;\">0.99032 </td><td style=\"text-align: right;\">0.510151</td><td style=\"text-align: right;\">0.720446</td><td style=\"text-align: right;\">0.555454</td><td style=\"text-align: right;\">0.535795</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.456242</td><td style=\"text-align: right;\"> 1.74043 </td><td style=\"text-align: right;\"> 0.258427</td><td style=\"text-align: right;\">1.45223 </td><td style=\"text-align: right;\">-0.0513728</td><td style=\"text-align: right;\">0.675328</td><td style=\"text-align: right;\">-0.797161 </td><td style=\"text-align: right;\">-1.34763 </td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.56858 </td><td style=\"text-align: right;\">-0.482712  </td><td style=\"text-align: right;\">-1.73738  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.539333</td><td style=\"text-align: right;\"> 1.17621  </td><td style=\"text-align: right;\"> 1.06666 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.980687</td><td style=\"text-align: right;\">-0.125384  </td><td style=\"text-align: right;\"> 0.0869597</td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.994118</td><td style=\"text-align: right;\">0.960552</td><td style=\"text-align: right;\">1.00353 </td><td style=\"text-align: right;\">0.57609 </td><td style=\"text-align: right;\">0.876509</td><td style=\"text-align: right;\">0.85138 </td><td style=\"text-align: right;\">0.801164</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">0.933712</td><td style=\"text-align: right;\"> 1.35084 </td><td style=\"text-align: right;\"> 0.773338</td><td style=\"text-align: right;\">0.532638</td><td style=\"text-align: right;\">-0.679537 </td><td style=\"text-align: right;\">0.718017</td><td style=\"text-align: right;\"> 0.745618 </td><td style=\"text-align: right;\">-1.4962  </td><td style=\"text-align: right;\">1.08654</td><td style=\"text-align: right;\">0.274218</td><td style=\"text-align: right;\"> 1.07537   </td><td style=\"text-align: right;\"> 1.56341  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.39146 </td><td style=\"text-align: right;\">-0.59422  </td><td style=\"text-align: right;\"> 0.170209</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">0.573711</td><td style=\"text-align: right;\"> 2.12157   </td><td style=\"text-align: right;\"> 0.256763 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.625972</td><td style=\"text-align: right;\">0.773067</td><td style=\"text-align: right;\">0.987348</td><td style=\"text-align: right;\">0.674946</td><td style=\"text-align: right;\">0.829309</td><td style=\"text-align: right;\">0.645423</td><td style=\"text-align: right;\">0.597715</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">0.7335  </td><td style=\"text-align: right;\">-0.998372</td><td style=\"text-align: right;\">-1.68702 </td><td style=\"text-align: right;\">0.951169</td><td style=\"text-align: right;\">-0.591779 </td><td style=\"text-align: right;\">1.14912 </td><td style=\"text-align: right;\">-0.942724 </td><td style=\"text-align: right;\">-0.424039</td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">1.04185 </td><td style=\"text-align: right;\"> 1.10063   </td><td style=\"text-align: right;\"> 1.27434  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.713549</td><td style=\"text-align: right;\"> 0.0201984</td><td style=\"text-align: right;\"> 0.343287</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.44706 </td><td style=\"text-align: right;\"> 0.165271  </td><td style=\"text-align: right;\"> 1.40599  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.798081</td><td style=\"text-align: right;\">0.852638</td><td style=\"text-align: right;\">0.990337</td><td style=\"text-align: right;\">0.799596</td><td style=\"text-align: right;\">0.918739</td><td style=\"text-align: right;\">1.27283 </td><td style=\"text-align: right;\">1.07795 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">0.968118</td><td style=\"text-align: right;\"> 1.719   </td><td style=\"text-align: right;\"> 0.030934</td><td style=\"text-align: right;\">1.80122 </td><td style=\"text-align: right;\">-0.867323 </td><td style=\"text-align: right;\">0.631357</td><td style=\"text-align: right;\">-0.810034 </td><td style=\"text-align: right;\"> 1.20648 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.88699 </td><td style=\"text-align: right;\"> 0.00103165</td><td style=\"text-align: right;\"> 1.57395  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.02721 </td><td style=\"text-align: right;\"> 0.512643 </td><td style=\"text-align: right;\"> 0.381009</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.08511 </td><td style=\"text-align: right;\"> 0.54837   </td><td style=\"text-align: right;\">-0.86704  </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.844315</td><td style=\"text-align: right;\">1.03113 </td><td style=\"text-align: right;\">1.32327 </td><td style=\"text-align: right;\">1.11639 </td><td style=\"text-align: right;\">0.728902</td><td style=\"text-align: right;\">0.805447</td><td style=\"text-align: right;\">1.19234 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[5000 rows x 29 columns]</pre>"
      ],
      "text/plain": [
       "  response        x1         x2         x3        x4          x5        x6          x7         x8       x9       x10          x11         x12      x13       x14         x15        x16      x17       x18          x19         x20      x21       x22       x23       x24       x25       x26       x27       x28\n",
       "----------  --------  ---------  ---------  --------  ----------  --------  ----------  ---------  -------  --------  -----------  ----------  -------  --------  ----------  ---------  -------  --------  -----------  ----------  -------  --------  --------  --------  --------  --------  --------  --------\n",
       "         0  0.623878   0.459659  -0.316512  1.55701    0.644784   0.455929  -2.24983    -0.361949  0        0.832978   1.41147      1.52846    0        0.722857   1.00964     0.999539  0        1.19099    0.81404     -0.879803   3.10196  0.583344  0.790246  1.04087   0.848858  0.229702  0.65594   0.677857\n",
       "         0  1.68204    0.774251   1.32875   0.234729  -0.55783    0.442921  -0.0832048   1.08119   2.17308  1.14585    0.16228     -0.268187   0        1.21407    0.194966   -1.15627   2.54822  1.01915   -0.759163     0.136347   0        0.94183   0.941976  0.98816   0.86435   0.835132  0.767871  0.833013\n",
       "         1  1.09403   -0.88734    0.949229  0.410261  -1.55868    0.523352   0.131675    0.304513  0        1.11916    1.09383     -0.396352   2.21487  0.6289     0.628245    1.45775   0        0.523082   0.508394     0.988137   0        0.929989  0.973742  0.989141  0.780519  0.749821  0.887545  0.925278\n",
       "         0  1.33871   -0.899027  -1.25534   0.884285  -0.747925   0.547445  -0.79518     0.174235  2.17308  0.771663  -0.31855      1.02356    2.21487  0.408495  -1.1431      0.139699  0        1.29395   -1.34131      1.61685    0        0.79204   0.76921   0.984082  1.06928   0.700852  0.83083   0.71671\n",
       "         0  0.699095   1.43363   -1.72253   0.650113  -0.167574   0.967464   0.737696   -0.886391  2.17308  1.66797    0.446892     0.851008   0        0.59641    0.156736    0.340513  0        0.694684  -0.00046069  -1.14949    3.10196  0.714182  0.839843  0.984067  0.917766  0.388553  0.91664   0.886331\n",
       "         1  0.842208  -0.144202  -1.702     0.685875   0.544338   0.578774  -0.221837   -0.586474  1.08654  0.909401   2.81316     -0.0706666  0        1.54986   -0.85182     1.58811   0        1.14986    0.590011     0.0597691  0        0.872279  0.684341  0.99032   0.510151  0.720446  0.555454  0.535795\n",
       "         1  0.456242   1.74043    0.258427  1.45223   -0.0513728  0.675328  -0.797161   -1.34763   2.17308  0.56858   -0.482712    -1.73738    0        0.539333   1.17621     1.06666   0        0.980687  -0.125384     0.0869597  3.10196  0.994118  0.960552  1.00353   0.57609   0.876509  0.85138   0.801164\n",
       "         0  0.933712   1.35084    0.773338  0.532638  -0.679537   0.718017   0.745618   -1.4962    1.08654  0.274218   1.07537      1.56341    0        0.39146   -0.59422     0.170209  2.54822  0.573711   2.12157      0.256763   0        0.625972  0.773067  0.987348  0.674946  0.829309  0.645423  0.597715\n",
       "         0  0.7335    -0.998372  -1.68702   0.951169  -0.591779   1.14912   -0.942724   -0.424039  2.17308  1.04185    1.10063      1.27434    0        0.713549   0.0201984   0.343287  2.54822  1.44706    0.165271     1.40599    0        0.798081  0.852638  0.990337  0.799596  0.918739  1.27283   1.07795\n",
       "         0  0.968118   1.719      0.030934  1.80122   -0.867323   0.631357  -0.810034    1.20648   0        0.88699    0.00103165   1.57395    0        1.02721    0.512643    0.381009  2.54822  1.08511    0.54837     -0.86704    3.10196  0.844315  1.03113   1.32327   1.11639   0.728902  0.805447  1.19234\n",
       "[5000 rows x 29 columns]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
